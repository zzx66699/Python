{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.random as rd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### The purpose of regression analysis\n",
    "Regression analysis is primarily used for two conceptually distinct purposes: to infer relationships between the independent and dependent variables; and prediction (or forecasting). The former is named **explanatory modeling**, while the latter is the so called **predictive modeling**. These two purposes in some textbooks are described as **interpretation** and **prediction**.\n",
    "\n",
    "Take the NBA draft case we discussed in tutorials for example\n",
    "- **Explanatory modeling** explores the influence of players' weights (or heights) on their possible draft rounds;\n",
    "- **Predictive modeling** predicts the draft round of a new player given his weight and height. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bias and variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## The general expression and terminology <a id=\"section3\"></a>\n",
    " \n",
    " A linear regression model can be generalized as the equation\n",
    " \n",
    " $$\n",
    " y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_p x_p + u,\n",
    " $$\n",
    " \n",
    "where $\\beta_0, \\beta_1, ..., \\beta_p$ are parameters of the model, and the table below gives the terminology of regression models.\n",
    "\n",
    "$y$ |   $x_1, x_2, ..., x_p$  \n",
    ":--------|:--------\n",
    "**Dependent variable** | **Independent variables** \n",
    "**Explained variable** | **Explanatory variables**\n",
    "**Response variable** | **Control variables**\n",
    "**Predicted variable** | **Predictor variables**\n",
    "**Regressand** | **Regressors**\n",
    "\n",
    "Please note that these names for $x_1, x_2, ..., x_p$ and $y$ may be used interchangeably. Also notice that the term \"independent\" in the table above does not refer to the probabilistic independence in statistics.  \n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Notes: components of a linear regression model:</b> \n",
    "    <li> The variable $u$ is called the <b>error term</b> or <b>disturbance</b>. It represents factors other than $x_1, x_2, ..., x_p$ that affect the dependent variable $y$. You may consider $u$ as \"unobserved\" factors in the regression model. It is typically assumed that $\\mathbb{E}(u|x_1, x_2, ..., x_p)=\\mathbb{E}(u)=0$, which at least requires all factors in the unobserved error term $u$ be uncorrelated with the explanatory variables. \n",
    "    <li> The term $\\beta_0$ is called the <b>intercept (parameter)</b>, or <b>constant term</b>. \n",
    "    <li> The term $\\beta_j$, where $j=1, 2, ..., p$, is the <b>slope parameter</b>, indicating the relationship between $x_j$ and $y$. \n",
    "</div>\n",
    "\n",
    "In explanatory modeling, we are interested in parameters of the **population regression function (PRF)**, expressed as\n",
    "\n",
    "$$\n",
    "\\mathbb{E}(y|x_1, x_2, ..., x_p)=\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 +...+ \\beta_p x_p, \n",
    "$$\n",
    "where the error term $u$ is canceled since according to our assumption the conditional expectation of it is $\\mathbb{E}(u|x_1, x_2, ..., x_p)=0$. \n",
    "\n",
    "Please note the differences in the following notations related to $y$:\n",
    "- $y$: the dependent variable.\n",
    "- $y_i$: the $i$th observation of the dependent variable $y$ in the sample dataset.\n",
    "- $\\hat{y}$: the **fitted values** for $y$, expressed as the **sample regression function (SRF)** $\\hat{y}=\\hat{\\beta}_0 + \\hat{\\beta}_1 x_1 + \\hat{\\beta}_2 x_2 + ... + \\hat{\\beta}_{p}x_p$, where $\\hat{\\beta}_0, \\hat{\\beta}_1, \\hat{\\beta}_2, ..., \\hat{\\beta}_p$ are estimates of the true values $\\beta_0, \\beta_1, \\beta_2, ..., \\beta_p$, respectively, based on the data sample. The $i$th fitted value of $\\hat{y}$ is thus written as $\\hat{y}_i$. \n",
    "- $\\bar{y}$: the sample average of the dependent variable $y$.\n",
    "\n",
    "Similarly, for the independent variable $x$, we have the following notations:\n",
    "- $x_j$: the $j$th independent variable.\n",
    "- $x_{ij}$ the $i$ observation of the $j$th independent variable in the sample dataset\n",
    "- $\\bar{x}_j$: the sample average of $j$th independent variables $x_j$. \n",
    "\n",
    "The notations for the error term $u$ are:\n",
    "- $u$: the error term of the regression model.\n",
    "- $\\hat{u}_i$: the **residual** for observation $i$, expressed as $\\hat{u}_i=y_i-\\hat{y}_i$. \n",
    "\n",
    "You may notice that we can summarize most of these notations as follows.\n",
    "\n",
    "Notation Types | Notations   \n",
    ":-------------|:--------------\n",
    "Variables | $x_j$, $y$, $u$\n",
    "Data samples (the $i$th) | $x_{ij}$, $y_i$\n",
    "Sample averages | $\\bar{x}_j$, $\\bar{y}$ \n",
    "Estimates from data | $\\hat{y}$, $\\hat{u}_i$, $\\hat{\\beta}_0$, $\\hat{\\beta}_j$\n",
    "\n",
    "The following figure illustrates these notations for a simple linear regression model, where only one independent variable $x_1$ is considered. \n",
    "\n",
    "<img src=\"https://github.com/XiongPengNUS/dao_resources/blob/main/slr_notations.png?raw=true\">\n",
    "\n",
    "On the website [Programming for Business Analytics](https://share.streamlit.io/xiongpengnus/learn_dao/main/web.py), you may find an interactive data visual where the dataset is randomly generated assuming $\\beta_0=1.0$ and $\\beta_1=5.0$ for illustrating these notations.\n",
    "\n",
    "Please note that the above examples are \"cheating\" cases, as we assume that we know the parameters of the PRF. In real applications, the PRF is unknown and we are supposed to use have a sample dataset. It is our ultimate goal to infer the parameters of the PRF from the sample data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple linear regression <a id=\"section4\"></a>\n",
    "\n",
    "To begin with, we will use simple linear regression models in the following general form\n",
    "\n",
    "$$\n",
    "y = \\beta_0 + \\beta_1 x_1 + u\n",
    "$$\n",
    "\n",
    "to introduce how to estimate model parameters and how to interpret results. \n",
    "\n",
    "### The ordinary least squares (OLS) method  <a id=\"subsection4.1\"></a>\n",
    "\n",
    "The ordinary least squares (OLS) method is a commonly used method to estimate coefficients of regression models. The intuition of OLS is to minimize the overall residuals $\\hat{u}_i$, or the differences between the observation $y_i$ and its fitted value $\\hat{y}_i$. Mathematically, it minimizes the **sum of squared residuals (SSR)**, such that\n",
    "$$\n",
    "\\min~\\text{SSR} = \\min\\sum\\limits_{i=1}^n\\hat{u}_i^2 = \\min\\sum\\limits_{i=1}^n(y_i - \\hat{y}_i)^2. \n",
    "$$\n",
    "\n",
    "The general procedure of applying this package for linear regression models can be summarized into four lines of code:\n",
    "1. Import the module <code>statsmodels.formula.api</code>;\n",
    "2. Define a linear regression model by the <code>ols()</code> function. The formula of the regression model is specified by a string, where the dependent and independent variables are indicated by the corresponding column labels of the data table. \n",
    "3. Calculate the fitted regression model by the <code>fit()</code> method of the regression model object. \n",
    "4. Print the results exported by the method <code>summary()</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.646\n",
      "Model:                            OLS   Adj. R-squared:                  0.627\n",
      "Method:                 Least Squares   F-statistic:                     32.92\n",
      "Date:                Sun, 19 Sep 2021   Prob (F-statistic):           1.94e-05\n",
      "Time:                        14:50:30   Log-Likelihood:                -23.290\n",
      "No. Observations:                  20   AIC:                             50.58\n",
      "Df Residuals:                      18   BIC:                             52.57\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.2819      0.406      3.157      0.005       0.429       2.135\n",
      "x              4.2315      0.738      5.738      0.000       2.682       5.781\n",
      "==============================================================================\n",
      "Omnibus:                        0.841   Durbin-Watson:                   1.979\n",
      "Prob(Omnibus):                  0.657   Jarque-Bera (JB):                0.799\n",
      "Skew:                          -0.271   Prob(JB):                        0.671\n",
      "Kurtosis:                       2.185   Cond. No.                         5.06\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('xydata.csv')\n",
    "\n",
    "model = smf.ols('y ~ x',    # Model formula: dependent variable y, independent variable x\n",
    "                data=data)  # Variable 'data' as the dataset\n",
    "result = model.fit()        # Calculate the fitted model parameters\n",
    "print(result.summary())     # Print the summary of results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goodness-of-fit <a id=\"subsection4.2\"></a>\n",
    "\n",
    "Recalling that in the OLS method, our goal is to minimize the **sum of squared residuals (SSR)**, expressed as\n",
    "$$\n",
    "\\text{SSR} = \\sum\\limits_{i=1}^n\\hat{u}_i^2 = \\sum\\limits_{i=1}^n(y_i - \\hat{y}_i)^2. \n",
    "$$\n",
    "Besides SSR, we introduce the other two terms called the **total sum of squares (SST)** and the **explained sum of squares (SSE)**, expressed below\n",
    "$$\n",
    "\\text{SST} = \\sum\\limits_{i=1}^n(y_i - \\bar{y})^2 \\\\\n",
    "\\text{SSE} = \\sum\\limits_{i=1}^n(\\hat{y}_i - \\bar{y})^2.\n",
    "$$\n",
    "Given an arbitrary dataset, the following equation always holds. \n",
    "$$\n",
    "\\text{SST} = \\text{SSE} + \\text{SSR}\n",
    "$$\n",
    "The intuition of this equation is that the total variation of the dependent variable $y$ (SST) can be attributed to 1) the linear effect of the independent variable $x$ (SSE); and 2) the variation of the error term, which cannot be explained by the fitted values of $\\hat{y}$. \n",
    "\n",
    "In regression analysis, we are usually interested in the ratio of the explained variation SSE compared to the total variation SST. This ratio is referred to as the **coefficient of determination**, denoted by $R^2$.\n",
    "$$\n",
    "R^2 = \\frac{\\text{SSE}}{\\text{SST}} = 1-\\frac{\\text{SSR}}{\\text{SST}}.\n",
    "$$\n",
    "\n",
    "This term (can be found from the right-top corner of the summary table) is interpreted as the proportion of the sample variation in $y_i$ that is explained by the OLS regression line. Intuitively speaking, it reflects how well the regression line can capture the linear trend of the sample data, and larger values of $R^2$ is commonly preferred, but this is not always true, as we discuss in the next lecture. \n",
    "\n",
    "> *Students who are first learning econometrics tend to put too much weight on\n",
    "the size of the $R^2$ in evaluating regression equations. For now, be aware that\n",
    "using $R^2$ as the main gauge of success for an econometric analysis can lead\n",
    "to trouble.* - [Introductory Econometrics: a modern approach](https://economics.ut.ac.ir/documents/3030266/14100645/Jeffrey_M._Wooldridge_Introductory_Econometrics_A_Modern_Approach__2012.pdf) (Chapter 2)\n",
    "\n",
    "### Expected values and variances of the OLS estimates <a id=\"subsection4.3\"></a>\n",
    "Please refer to the reference book [Introductory Econometrics: a modern approach](https://economics.ut.ac.ir/documents/3030266/14100645/Jeffrey_M._Wooldridge_Introductory_Econometrics_A_Modern_Approach__2012.pdf), page 45 to 56. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ceteris paribus analysis<a id=\"section5\"></a>\n",
    "The notion of **ceteris paribus**—which means \"other (relevant) factors being equal\"—plays an important role in causal analysis. Recalling the condo price example we saw in previous lectures, in order to better \"isolate\" the influence of condo types (resale or new sale) on the prices, we need to adopt the ceteris paribus analysis where other factors, like condo sizes, are held equal. \n",
    "\n",
    "The simple regression models are considered ineffective in dealing with ceteris paribus analysis, as mentioned in the reference book. \n",
    "\n",
    ">*The primary drawback in using simple regression analysis for empirical work is that it is very difficult to draw ceteris paribus conclusions about how $x$ affects $y$: the key assumption, <b>SLR.4</b>$-$that all other factors affecting y are uncorrelated with $x-$is often unrealistic.*\n",
    "> \n",
    ">*Multiple regression analysis is more amenable to ceteris paribus analysis because\n",
    "it allows us to explicitly control for many other factors that simultaneously affect the\n",
    "dependent variable. This is important both for testing economic theories and for evaluating policy effects when we must rely on nonexperimental data. Because multiple regression models can accommodate many explanatory variables that may be correlated, we can hope to infer causality in cases where simple regression analysis would be misleading.* - [Introductory Econometrics: a modern approach](https://economics.ut.ac.ir/documents/3030266/14100645/Jeffrey_M._Wooldridge_Introductory_Econometrics_A_Modern_Approach__2012.pdf) (Chapter 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple regression analysis<a id=\"section6\"></a>\n",
    "\n",
    "### The OLS method for multiple regression models <a id=\"subsection6.1\"></a>\n",
    "\n",
    "We will still use functions imported from the <code>statsmodels</code> to implement the OLS method for multiple regression models. The Python code is very similar to the simple regression cases, and the only difference is that we need to use the <code>+</code> operator in the formula string to include multiple independent variables. \n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Example 1:</b> The 'advertising.csv' dataset consists of the sales of a product in 200 different markets (in thousands of units), along with advertising budgets (in thousands of dollars) for the product in each of those markets for three different media: TV, radio, and newspaper. Please use the following two linear regression models to explore how the advertising budgets affect the sales of the product:\n",
    "\\begin{align}\n",
    "    \\textbf{Simple regression:   }& y_{\\text{sales}} = \\beta_0 + \\beta_1 x_{\\text{newspaper}} + u \\\\\n",
    "    \\textbf{Multiple regressoin: }& y_{\\text{sales}} = \\beta_0 + \\beta_1 x_{\\text{TV}} + \\beta_2 x_{\\text{radio}} + \\beta_3 x_{\\text{newspaper}} + u\n",
    "\\end{align}\n",
    "</div>\n",
    "\n",
    "The dataset is read from the file \"advertising.csv\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  radio  newspaper  sales\n",
       "0  230.1   37.8       69.2   22.1\n",
       "1   44.5   39.3       45.1   10.4\n",
       "2   17.2   45.9       69.3    9.3\n",
       "3  151.5   41.3       58.5   18.5\n",
       "4  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('advertising.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simple regression model can be implemented as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  sales   R-squared:                       0.052\n",
      "Model:                            OLS   Adj. R-squared:                  0.047\n",
      "Method:                 Least Squares   F-statistic:                     10.89\n",
      "Date:                Sun, 19 Sep 2021   Prob (F-statistic):            0.00115\n",
      "Time:                        14:50:30   Log-Likelihood:                -608.34\n",
      "No. Observations:                 200   AIC:                             1221.\n",
      "Df Residuals:                     198   BIC:                             1227.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     12.3514      0.621     19.876      0.000      11.126      13.577\n",
      "newspaper      0.0547      0.017      3.300      0.001       0.022       0.087\n",
      "==============================================================================\n",
      "Omnibus:                        6.231   Durbin-Watson:                   1.983\n",
      "Prob(Omnibus):                  0.044   Jarque-Bera (JB):                5.483\n",
      "Skew:                           0.330   Prob(JB):                       0.0645\n",
      "Kurtosis:                       2.527   Cond. No.                         64.7\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model_sr = smf.ols('sales ~ newspaper', data=data)\n",
    "result_sr = model_sr.fit()\n",
    "print(result_sr.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The multiple regression model can be implemented in the similar way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  sales   R-squared:                       0.897\n",
      "Model:                            OLS   Adj. R-squared:                  0.896\n",
      "Method:                 Least Squares   F-statistic:                     570.3\n",
      "Date:                Sun, 19 Sep 2021   Prob (F-statistic):           1.58e-96\n",
      "Time:                        14:50:30   Log-Likelihood:                -386.18\n",
      "No. Observations:                 200   AIC:                             780.4\n",
      "Df Residuals:                     196   BIC:                             793.6\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      2.9389      0.312      9.422      0.000       2.324       3.554\n",
      "TV             0.0458      0.001     32.809      0.000       0.043       0.049\n",
      "radio          0.1885      0.009     21.893      0.000       0.172       0.206\n",
      "newspaper     -0.0010      0.006     -0.177      0.860      -0.013       0.011\n",
      "==============================================================================\n",
      "Omnibus:                       60.414   Durbin-Watson:                   2.084\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              151.241\n",
      "Skew:                          -1.327   Prob(JB):                     1.44e-33\n",
      "Kurtosis:                       6.332   Cond. No.                         454.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model_mr = smf.ols('sales ~ TV + radio + newspaper', data=data)\n",
    "result_mr = model_mr.fit()\n",
    "print(result_mr.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为啥只考虑newspaper时影响是正的，多个就是负的？\n",
    "当newpaper增加1时，有可能tv和radio也会增加，是没有控制这些value的；而hold the value of TV and radio, 而增加newspaper，会减少"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected values and variances of the OLS estimators <a id=\"subsection6.2\"></a>\n",
    "Please refer to the reference book [Introductory Econometrics: a modern approach](https://economics.ut.ac.ir/documents/3030266/14100645/Jeffrey_M._Wooldridge_Introductory_Econometrics_A_Modern_Approach__2012.pdf), page 83 to 102. \n",
    "\n",
    "### Interpretation and inference of model parameters<a id=\"subsection6.3\"></a>\n",
    "\n",
    "In explanatory modeling, we are interested in the parameters of a regression model, because they reflect how the independent variables affect the dependent variables. In the equation \n",
    "$$\n",
    "y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3 + ... \\beta_p x_p + u, \n",
    "$$\n",
    "notice that for an independent variable $x_j$, we would have $\\Delta y = \\beta_j \\Delta x_j$ if $\\Delta u = 0$ and holding all other independent variables fixed. In other words, the slope parameter $\\beta_j$ measures the change in $y$ with respect to $x_j$, holding other factors fixed. This is why the multiple regression models are so useful in ceteris paribus analysis. \n",
    "\n",
    "Following the logic above, we may also conclude that the slope parameter $\\beta_j$ determines whether the linear relationship is positive ($\\beta_j>0$) or negative ($\\beta_j <0$). A special case is that $\\beta_j=0$, indicating that there is no linear relationship between the independent variable $x_j$ and the dependent variable $y$. \n",
    "\n",
    "In data science applications, all parameters $\\beta_j$ of the PRF are unknown, and our goal is to infer the values of these parameters from sample data. Statistical inference of these population parameters are demonstrated by the example below.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Example 2:</b> Based on the multiple regression model in <b>Example 1</b>, explore how advertisement for different media affects the product sales.\n",
    "</div>\n",
    "\n",
    "The interpretation of each columns of the model parameters:\n",
    "1. The first column gives the estimates of model parameters. They are $\\hat{\\beta}_0=2.9389$, $\\hat{\\beta}_1=0.0458$, $\\hat{\\beta}_2=0.1885$, and $\\hat{\\beta}_3=-0.0010$. These estimates can be retrieved by the attribute <code>params</code> of the object <code>result_mr</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept    2.938889\n",
       "TV           0.045765\n",
       "radio        0.188530\n",
       "newspaper   -0.001037\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_mr.params        # Estimates of model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在多元回归中，系数>0,并不代表correlation between x和y是正相关；反过来，正相关也不一定系数小于0。所有都是Ceteris paribus。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The second column gives the standard errors of model parameter estimators. For this example, $\\text{SE}(\\hat{\\beta}_0)=0.312$, $\\text{SE}(\\hat{\\beta}_1)=0.001$, $\\text{SE}(\\hat{\\beta}_2)=0.009$, and $\\text{SE}(\\hat{\\beta}_2)=0.006$. The standard error information can be retrieved by the attribute <code>bse</code> of the object <code>result_mr</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept    0.311908\n",
       "TV           0.001395\n",
       "radio        0.008611\n",
       "newspaper    0.005871\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_mr.bse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. The third column are the $t$ values, expressed as \n",
    "$$\n",
    "t_j = \\frac{\\hat{\\beta}_j}{\\text{SE}(\\hat{\\beta}_j)},~~j=0, 1, ..., p.\n",
    "$$\n",
    "These $t$ values will be used in two-tailed hypothesis tests where \n",
    "$$\n",
    "\\begin{cases}\n",
    "H_0:~ \\beta_j = 0 \\\\\n",
    "H_a:~ \\beta_j \\not= 0\n",
    "\\end{cases}\n",
    "~~~~~j=0, 1, ..., p.\n",
    "$$\n",
    "It can be seen that such hypothesis tests are used to verify if the independent variable $x_j$ has a linear relationship with the dependent variable $y$. \n",
    "\n",
    "4. The fourth column calculates the corresponding $P$-values of the two-tailed hypothesis tests. If the $P$-value for $x_j$ is lower than the significance level $\\alpha$ (typically $\\alpha=0.05$), we have sufficient evidence to reject the null hypothesis $H_0:~\\beta_j=0$, or we say $x_j$ is **statistically significant** at the $\\alpha$ significance level. The conclusion is hence that the model parameter $\\beta_j$ is unlikely to be zero so $x_j$ has some linear relationship with $y$. For this example, our conclusion would be:\n",
    "    - Variables $x_{\\text{TV}}$ and $x_{\\text{radio}}$ are statistically significant at the $0.05$ significance level. Advertising for TV and radio are likely to promote sales of the product.\n",
    "    - The variable $x_{\\text{newspaper}}$ is statistically insignificant. There might be very little effect of advertising for newspapers on the sales.\n",
    "    \n",
    "5. The fifth and sixth columns give the confidence intervals of each $\\hat{\\beta}_j$, given the confidence level to be $1-\\alpha=0.95$.\n",
    "\n",
    "If you are not familiar with the concepts of confidence intervals or hypothesis testing, please refer to the reference book [Introductory Econometrics: a modern approach](https://economics.ut.ac.ir/documents/3030266/14100645/Jeffrey_M._Wooldridge_Introductory_Econometrics_A_Modern_Approach__2012.pdf), page 770 to 783. Alternatively, you may visit the website [Programming for Business Analytics](https://share.streamlit.io/xiongpengnus/learn_dao/main/web.py) to review the related concepts.\n",
    "\n",
    "### Goodness-of-fit<a id=\"subsection6.4\"></a>\n",
    "\n",
    "The SST, SSE, and SSR take the same expressions as the SLR case, so does the $R^2$ value for the percentage of variation explained by the regression line. However, the $R^2$ value is not an effective tool in determining model performance, and the reasons are given in the reference book.\n",
    ">*An important fact about $R^2$ is that it never decreases, and it usually increases when\n",
    "another independent variable is added to a regression.* \n",
    ">...\n",
    ">*The fact that $R^2$ never decreases when any variable is added to a regression makes\n",
    "it a poor tool for deciding whether one variable or several variables should be added to\n",
    "a model.* - [Introductory Econometrics: a modern approach](https://economics.ut.ac.ir/documents/3030266/14100645/Jeffrey_M._Wooldridge_Introductory_Econometrics_A_Modern_Approach__2012.pdf) (Chapter 3)\n",
    "\n",
    "This is why sometimes we would use the adjusted $R^2$ to compare two models in terms of the goodness-of-fit. The primary attractiveness of the adjusted $R^2$ is that it imposes a penalty for adding additional independent variables to a model, so we will not always prefer models with higher complexity. There is no need for you to derive the expression for the adjusted $R^2$ value. It is displayed at the top-right conner of the summary table of the regression model.就是说r只要variable增加了，r都会增加，所以要用adjusted r^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonlinearity<a id=\"section7\"></a>\n",
    "The name \"linear regression\" is sometimes misleading because it seems to imply that this method is only capable of capturing linear relationship between the dependent and independent variable. **The key meaning of the term \"linear\" is that the equation is linear in the parameters $\\beta_0$, $\\beta_1$, ..., and $\\beta_p$. There are no restrictions on how $y$ and each $x_j$ relate to the original dependent and independent variables of interest.** In other words, the dependent and independent variables could be functions or other transformations of $y$ and $x_j$, respectively, as long as the equation is linear in parameters $\\beta_0$, $\\beta_1$, ..., $\\beta_p$. The following examples are provided as valid linear regression models. \n",
    "就是说这些variable不linear，但是parameter是linear就行了\n",
    "\\begin{align}\n",
    "& y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_1^2 + \\beta_3x_2 \\\\\n",
    "& y = \\beta_0 + \\beta_1 \\log(x_1) \\\\\n",
    "& \\sqrt{y} = \\beta_0 + \\beta_1 x_1 + \\beta_2 \\log(x_1).  \\\\\n",
    "\\end{align}\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Example 3:</b> The 'wage.csv' dataset consists of the wages of a number of working individuals for the year 1976. Considering all females in the dataset, run the following two models and interpret the results:\n",
    "\\begin{align}\n",
    "    \\textbf{Model 1: }& y_{\\text{wage}} = \\beta_0 + \\beta_1 x_{\\text{exper}} + u \\\\\n",
    "    \\textbf{Model 2: }& y_{\\text{wage}} = \\beta_0 + \\beta_1 x_{\\text{exper}} + \\beta_2 \\sqrt{x_{\\text{exper}}} + u\n",
    "\\end{align}\n",
    "</div>\n",
    "In this example, we only consider the independent variable $x_{\\text{exper}}$ and its nonlinear transformations, because it is easier for us to visualize the results. The following code segment is used to take a subset of the sample data that contains only females.\n",
    "两个要放在一起解释"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wage</th>\n",
       "      <th>educ</th>\n",
       "      <th>exper</th>\n",
       "      <th>gender</th>\n",
       "      <th>married</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.10</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.24</td>\n",
       "      <td>12.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.60</td>\n",
       "      <td>12.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.25</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    wage  educ  exper  gender  married\n",
       "0   3.10  11.0    2.0  Female    False\n",
       "1   3.24  12.0   22.0  Female     True\n",
       "7   5.00  12.0    5.0  Female    False\n",
       "8   3.60  12.0   26.0  Female    False\n",
       "10  6.25  16.0    8.0  Female    False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wage = pd.read_csv('wage.csv')\n",
    "wage_female = wage.loc[wage['gender']=='Female']\n",
    "wage_female.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 1** is specified and implemented by the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   wage   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                 -0.004\n",
      "Method:                 Least Squares   F-statistic:                   0.01564\n",
      "Date:                Sun, 19 Sep 2021   Prob (F-statistic):              0.901\n",
      "Time:                        14:50:30   Log-Likelihood:                -590.91\n",
      "No. Observations:                 252   AIC:                             1186.\n",
      "Df Residuals:                     250   BIC:                             1193.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      4.6117      0.250     18.441      0.000       4.119       5.104\n",
      "exper         -0.0015      0.012     -0.125      0.901      -0.025       0.022\n",
      "==============================================================================\n",
      "Omnibus:                      180.041   Durbin-Watson:                   1.964\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1843.760\n",
      "Skew:                           2.815   Prob(JB):                         0.00\n",
      "Kurtosis:                      14.996   Cond. No.                         33.5\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model1 = smf.ols('wage ~ exper', data=wage_female)\n",
    "result1 = model1.fit()\n",
    "print(result1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is observed that the $P$-value for the parameter $\\beta_1$ as the slope of $x_{\\text{exper}}$ is 0.901, much larger than the significance level $\\alpha=0.05$, so we failed to reject the null hypothesis that $H_0:~\\beta_1=0$. In other words, The independent variable $x_{\\text{exper}}$ may have no linear relationship with the dependent variable $y_{\\text{wage}}$. Can we say that the working experience $x_{\\text{exper}}$ has no effect on the hourly wage $y_{\\text{wage}}$?\n",
    "\n",
    "This question could be answered by visualizing the relation between $x_{\\text{exper}}$ and $y_{\\text{wage}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 324x252 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4.5, 3.5))\n",
    "plt.scatter(wage_female['exper'], wage_female['wage'], \n",
    "            c='b', alpha=0.3)\n",
    "\n",
    "plt.xlabel('Working experience (years)', fontsize=13)\n",
    "plt.ylabel('Hourly wage (Dollars)', fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the diagram above, we observe that there is in fact some relation between $x_{\\text{exper}}$ and $y_{\\text{wage}}$, but this relation is not linear. The hourly wage increases at first then drops as working experience grows, and such a trend can be better captured if we include a nonlinear term, like a square root of $x_{\\text{exper}}$, into the regression model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   wage   R-squared:                       0.052\n",
      "Model:                            OLS   Adj. R-squared:                  0.045\n",
      "Method:                 Least Squares   F-statistic:                     6.850\n",
      "Date:                Sun, 19 Sep 2021   Prob (F-statistic):            0.00127\n",
      "Time:                        14:50:30   Log-Likelihood:                -584.17\n",
      "No. Observations:                 252   AIC:                             1174.\n",
      "Df Residuals:                     249   BIC:                             1185.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept          1.9159      0.769      2.493      0.013       0.402       3.430\n",
      "exper             -0.2067      0.057     -3.649      0.000      -0.318      -0.095\n",
      "np.sqrt(exper)     1.6542      0.447      3.699      0.000       0.773       2.535\n",
      "==============================================================================\n",
      "Omnibus:                      177.203   Durbin-Watson:                   1.938\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1807.206\n",
      "Skew:                           2.754   Prob(JB):                         0.00\n",
      "Kurtosis:                      14.907   Cond. No.                         123.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model2 = smf.ols('wage ~ exper + np.sqrt(exper)', data=wage_female)\n",
    "result2 = model2.fit()\n",
    "print(result2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the comparison between **Model 1** and **Model 2**, we have the following observations:\n",
    "1. **Model 2** has improved $R^2$ and adjusted $R^2$ values, so it is a better fit of the sample data.\n",
    "2. The SRF curves (please plot it by yourself) of both models also show that **Model 2** better capture the trend of the hourly wages.\n",
    "3. It has been shown that the linear term in **Model 1** is ineffective in capturing the nonlinear trend. For **Model 2**, $P$-values associated with slope parameters are all below $\\alpha=0.05$, suggesting that these parameters are unlikely to be zeros and there are some nonlinear relation between these variables. \n",
    "4. Please note that in this example, the ceteris paribus analysis is no longer valid because we can not hold the other term $\\sqrt{x_{\\text{exper}}}$ fixed while change the value of $x_{\\text{exper}}$. As a result, we need to consider $\\hat{\\beta}_1x_{\\text{exper}} + \\hat{\\beta}_2\\sqrt{x_{\\text{exper}}}$ as a whole when interpreting the effect of $x_{\\text{exper}}$ on the dependent variable $y_{\\text{wage}}$.\n",
    "\n",
    "In fact, the (adjusted) $R^2$ value can be further improved if we take logarithm of the dependent variable $y_{\\text{wage}}$. Let us call the new model **Model 3** and the formula is\n",
    "$$\n",
    "\\textbf{Model 3: } \\log\\left( y_{\\text{wage}}\\right)= \\beta_0 + \\beta_1 x_{\\text{exper}} + u,\n",
    "$$\n",
    "and please implement it by yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that although nonlinear transformation could improve the performance of regression models, it also increases the complexity of models, so they are no longer that straightforward to interpret. As a result, you need to be cautious when using nonlinear transformation in explanatory modeling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical variables and dummies<a id=\"section8\"></a>\n",
    "\n",
    "In previous lectures, we have been dealing with numerical (or quantitative) independent variables. In this section, we will focus on modeling categorical (or qualitative) variables and their interpretations in regression models.\n",
    "\n",
    "The following dataset 'condo.csv' is used as an example for explaining categorical variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>district_code</th>\n",
       "      <th>segment</th>\n",
       "      <th>type</th>\n",
       "      <th>area</th>\n",
       "      <th>level</th>\n",
       "      <th>remaining_years</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SEASCAPE</td>\n",
       "      <td>4388000</td>\n",
       "      <td>2028</td>\n",
       "      <td>4</td>\n",
       "      <td>CCR</td>\n",
       "      <td>Resale</td>\n",
       "      <td>2164</td>\n",
       "      <td>06 to 10</td>\n",
       "      <td>87.0</td>\n",
       "      <td>Nov-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COMMONWEALTH TOWERS</td>\n",
       "      <td>1300000</td>\n",
       "      <td>1887</td>\n",
       "      <td>3</td>\n",
       "      <td>RCR</td>\n",
       "      <td>Resale</td>\n",
       "      <td>689</td>\n",
       "      <td>16 to 20</td>\n",
       "      <td>93.0</td>\n",
       "      <td>Nov-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>THE TRILINQ</td>\n",
       "      <td>1755000</td>\n",
       "      <td>1304</td>\n",
       "      <td>5</td>\n",
       "      <td>OCR</td>\n",
       "      <td>Resale</td>\n",
       "      <td>1346</td>\n",
       "      <td>06 to 10</td>\n",
       "      <td>92.0</td>\n",
       "      <td>Nov-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>THE CREST</td>\n",
       "      <td>2085000</td>\n",
       "      <td>2201</td>\n",
       "      <td>3</td>\n",
       "      <td>RCR</td>\n",
       "      <td>Resale</td>\n",
       "      <td>947</td>\n",
       "      <td>01 to 05</td>\n",
       "      <td>92.0</td>\n",
       "      <td>Nov-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>THE ANCHORAGE</td>\n",
       "      <td>1848888</td>\n",
       "      <td>1468</td>\n",
       "      <td>3</td>\n",
       "      <td>RCR</td>\n",
       "      <td>Resale</td>\n",
       "      <td>1259</td>\n",
       "      <td>01 to 05</td>\n",
       "      <td>999.0</td>\n",
       "      <td>Nov-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name    price  unit_price  district_code segment    type  \\\n",
       "0             SEASCAPE  4388000        2028              4     CCR  Resale   \n",
       "1  COMMONWEALTH TOWERS  1300000        1887              3     RCR  Resale   \n",
       "2          THE TRILINQ  1755000        1304              5     OCR  Resale   \n",
       "3            THE CREST  2085000        2201              3     RCR  Resale   \n",
       "4        THE ANCHORAGE  1848888        1468              3     RCR  Resale   \n",
       "\n",
       "   area     level  remaining_years    date  \n",
       "0  2164  06 to 10             87.0  Nov-19  \n",
       "1   689  16 to 20             93.0  Nov-19  \n",
       "2  1346  06 to 10             92.0  Nov-19  \n",
       "3   947  01 to 05             92.0  Nov-19  \n",
       "4  1259  01 to 05            999.0  Nov-19  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condo = pd.read_csv('condo.csv')\n",
    "condo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These categorical variables are:\n",
    "- <code>district_code</code>: The district code indicating these condos' locations. Details can be found [here](https://www.mingproperty.sg/singapore-district-code/) \n",
    "- <code>segment</code>: The region segments of condos. There are three categories: core central region (CCR), outside central region (OCR), and the rest of central region (RCR).\n",
    "- <code>type</code>: Type transactions: resale or new sale.\n",
    "- <code>level</code>: Condo levels. This column can be converted to numeric values if necessary. \n",
    "\n",
    "Please note that whether a variable is categorical may depend on specific applications. For example, the column <code>date</code> is usually considered as time stamps, but in some rare cases it could also be recognized as categorical data. Another special case is the column <code>district_code</code> Although all values of this column are numerical, this variable is categorical as all numbers are used to indicate different categories. \n",
    "\n",
    "### Dummies for two categories <a id=\"subsection8.1\"></a>\n",
    "In regression models, the categorical information is captured by a **binary variable** or a **dummy variable**. Take the categorical variable <code>type</code> for example, the two categories are differentiated by a dummy variable $d_{\\text{resale}}$, where $d_{\\text{resale}}=1$ if <code>type='Resale'</code> and $d_{\\text{resale}}=0$ if <code>type='New Sale'</code>. The zero-one values of the dummy variable is then used in the regression model to address categorical variables. \n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Example 4:</b> Given the dataset 'condo.csv' and consider all condos that:\n",
    "    <li> in district 5, </li>\n",
    "    <li> has an area smaller than 1500 square feet, </li>\n",
    "    <li> has a tenure of no more than 99 years remaining. </li>\n",
    "    Run a regression model with the total price $y_{\\text{price}}$ being the dependent variable and the categorical variable $x_{\\text{type}}$ being the independent variable. \n",
    "</div>\n",
    "\n",
    "A zero-one dummy variable $d_{\\text{resale}}$ is used in the regression model to indicate the type of the condo. The formula for the regression model is thus given as\n",
    "$$\n",
    "y_{\\text{price}} = \\beta_0 + \\beta_1 d_{\\text{resale}} + u\n",
    "$$\n",
    "where the dummy variable $d_{\\text{resale}}=1$ if it is a resale condo, and $d_{\\text{resale}}=0$ if it is a new sale condo. Such a model can be implemented by the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "condo_subset = condo.loc[(condo['district_code']==5) & \n",
    "                         (condo['area']<1500) & \n",
    "                         (condo['remaining_years']<100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  price   R-squared:                       0.017\n",
      "Model:                            OLS   Adj. R-squared:                  0.016\n",
      "Method:                 Least Squares   F-statistic:                     24.39\n",
      "Date:                Sun, 19 Sep 2021   Prob (F-statistic):           8.82e-07\n",
      "Time:                        14:50:30   Log-Likelihood:                -19629.\n",
      "No. Observations:                1402   AIC:                         3.926e+04\n",
      "Df Residuals:                    1400   BIC:                         3.927e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept       1.067e+06   9793.835    108.907      0.000    1.05e+06    1.09e+06\n",
      "type[T.Resale]  7.965e+04   1.61e+04      4.938      0.000     4.8e+04    1.11e+05\n",
      "==============================================================================\n",
      "Omnibus:                      148.267   Durbin-Watson:                   1.723\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               65.902\n",
      "Skew:                           0.342   Prob(JB):                     4.89e-15\n",
      "Kurtosis:                       2.188   Cond. No.                         2.42\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model = smf.ols('price ~ type', condo_subset)\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the formula of the model is specified by the string <code>price ~ type</code>, where <code>price</code> and <code>type</code> are the column labels of the dependent and independent variables, respectively. As the users of the <code>statsmodels</code> package, we do not have to manually create the dummy variable $d_{\\text{resale}}$ by mapping the categories to the zero-one values. The package automatically creates the dummy variable $d_{\\text{resale}}$ and the estimated slope parameter ($\\hat{\\beta}_1$) of the dummy variable  is given by the row <code>type[T.Resale]</code>. The notation <code>[T.Resale]</code> means that the dummy variable is one if the categorical variable has the value <code>'Resale'</code>. \n",
    "\n",
    "Because the dummy variable $d_{\\text{resale}}$ takes zero or one, the fitted model can be written as follows under different categories:\n",
    "\\begin{align}\n",
    "\\text{Resale condos where }d_{\\text{resale}}=1: ~&\\hat{y}_{\\text{price}} = \\hat{\\beta}_0 + \\hat{\\beta}_1d_{\\text{resale}} = \\hat{\\beta}_0 + \\hat{\\beta}_1 \\\\\n",
    "\\text{New sale condos where }d_{\\text{resale}}=0: ~&\\hat{y}_{\\text{price}} = \\hat{\\beta}_0 + \\hat{\\beta}_1 d_{\\text{resale}}= \\hat{\\beta}_0.\n",
    "\\end{align}\n",
    "\n",
    "It can be seen that $\\hat{\\beta}_0$ is the fitted value of prices for new sale condos, and $\\hat{\\beta}_1$ is the amount of price change of resale condos compared with new condos. In this example, we have $\\hat{\\beta}_1=$7.965e+04, implying that the resale condos are roughly 80 thousand Dollars more expensive compared with new sale condos. As we mentioned in previous lectures, the counterintuitive result is due to confounding factors, which we will address by next using multiple regression analysis. \n",
    "\n",
    "Let us include <code>area</code> as another independent variable of the regression model, so the formula of the model is\n",
    "$$\n",
    "y_{\\text{price}} = \\beta_0 + \\beta_1 d_{\\text{resale}} + \\beta_2 x_{\\text{area}} + u\n",
    "$$\n",
    "and results are presented below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  price   R-squared:                       0.824\n",
      "Model:                            OLS   Adj. R-squared:                  0.824\n",
      "Method:                 Least Squares   F-statistic:                     3271.\n",
      "Date:                Sun, 19 Sep 2021   Prob (F-statistic):               0.00\n",
      "Time:                        14:50:30   Log-Likelihood:                -18424.\n",
      "No. Observations:                1402   AIC:                         3.685e+04\n",
      "Df Residuals:                    1399   BIC:                         3.687e+04\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept       1.887e+05   1.17e+04     16.087      0.000    1.66e+05    2.12e+05\n",
      "type[T.Resale] -1.614e+05   7465.490    -21.624      0.000   -1.76e+05   -1.47e+05\n",
      "area            1024.6680     12.803     80.035      0.000     999.553    1049.783\n",
      "==============================================================================\n",
      "Omnibus:                       74.849   Durbin-Watson:                   1.960\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              242.179\n",
      "Skew:                           0.163   Prob(JB):                     2.58e-53\n",
      "Kurtosis:                       5.010   Cond. No.                     3.54e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.54e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "model = smf.ols('price ~ type + area', condo_subset)\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fitted model would take different equations under the resale/new sale categories:\n",
    "\\begin{align}\n",
    "\\text{Resale condos where }d_{\\text{resale}}=1: ~&\\hat{y}_{\\text{price}} = \\hat{\\beta}_0 + \\hat{\\beta}_1d_{\\text{resale}} + \\hat{\\beta}_2x_{\\text{area}} = (\\hat{\\beta}_0 + \\hat{\\beta}_1) + \\hat{\\beta}_2x_{\\text{area}} \\\\\n",
    "\\text{New sale condos where }d_{\\text{resale}}=0: ~&\\hat{y}_{\\text{price}} = \\hat{\\beta}_0 + \\hat{\\beta}_1 d_{\\text{resale}} + \\hat{\\beta}_2x_{\\text{area}}= \\hat{\\beta}_0 + \\hat{\\beta}_2x_{\\text{area}}.\n",
    "\\end{align}\n",
    "so the interpretations of $\\hat{\\beta}_1$ are 1) the price difference between resale and new sale condos, holding the condo size fixed; and 2) the difference in the intercepts of the SRF curves for both categories.\n",
    "\n",
    "<img src=\"https://github.com/XiongPengNUS/dao_resources/blob/main/condo_price_areas_type.png?raw=true\">\n",
    "\n",
    "Based on the equations and graph above, we may also derive the interpretations of other model parameters as below:\n",
    "- $\\hat{\\beta}_0$: the intercept of the SRF for new sale condos.\n",
    "- $\\hat{\\beta}_2$: the slope parameter of $x_{\\text{area}}$ for both resale and new sale condos.\n",
    "\n",
    "### Dummies for multiple categories<a id=\"subsection8.2\"></a>\n",
    "In the condo price dataset, we have some categorical variables that have more than two categories, such as the variable <code>segment</code>. Generally speaking, a categorical variable with $m$ categories is expressed by $m-1$ dummy variables. The variable <code>segment</code> that has three categories (CCR, OCR, and RCR) therefore can be expressed by two dummy variables $d_{\\text{CCR}}$ and $d_{\\text{RCR}}$. The values of the dummy variables are determined as the following table. \n",
    "\n",
    "<b> </b> | $d_{\\text{OCR}}$ | $d_{\\text{RCR}}$\n",
    ":------|:------------|:-----------------\n",
    "**CCR** | 0 | 0 \n",
    "**OCR** | 1 | 0\n",
    "**RCR** | 0 | 1 \n",
    "\n",
    "The case of \"CCR\" is recognized as the **baseline**, or sometimes called the **reference** or **benchmark** case, where all dummy variables take the zero values. For the category \"OCR\" (\"RCR\"), the corresponding dummy variable $d_{\\text{OCR}}$ ($d_{\\text{RCR}}$) is one, while the other dummy variable $d_{\\text{RCR}}$ ($d_{\\text{OCR}}$) is zero. These dummy variables are used in regression models to capture categorical data information, as illustrated by the next Example.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Example 5:</b> Given the dataset 'condo.csv' and consider all <b>freehold</b> condos <b>smaller than 1500 square feet</b>, run a regression model with the total price $y_{\\text{price}}$ being the dependent variable and the categorical variable $x_{\\text{segment}}$ and the numerical variable $x_{\\text{area}}$ being the independent variables. \n",
    "</div>\n",
    "The model formula with dummy variables are given below:\n",
    "$$\n",
    "y_{\\text{price}} = \\beta_0 +\\beta_1 d_{\\text{OCR}} + \\beta_2 d_{\\text{RCR}} + \\beta_3 x_{\\text{area}} + u.\n",
    "$$\n",
    "\n",
    "Similar to the previous examples, we just need to use column labels to specify the model formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  price   R-squared:                       0.575\n",
      "Model:                            OLS   Adj. R-squared:                  0.575\n",
      "Method:                 Least Squares   F-statistic:                     2602.\n",
      "Date:                Sun, 19 Sep 2021   Prob (F-statistic):               0.00\n",
      "Time:                        14:50:39   Log-Likelihood:                -82693.\n",
      "No. Observations:                5767   AIC:                         1.654e+05\n",
      "Df Residuals:                    5763   BIC:                         1.654e+05\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept       9.327e+05   2.28e+04     40.958      0.000    8.88e+05    9.77e+05\n",
      "segment[T.OCR] -9.463e+05   1.32e+04    -71.914      0.000   -9.72e+05   -9.21e+05\n",
      "segment[T.RCR]  -4.94e+05   1.39e+04    -35.563      0.000   -5.21e+05   -4.67e+05\n",
      "area            1115.2906     19.260     57.906      0.000    1077.533    1153.048\n",
      "==============================================================================\n",
      "Omnibus:                     1744.835   Durbin-Watson:                   1.575\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             6787.529\n",
      "Skew:                           1.460   Prob(JB):                         0.00\n",
      "Kurtosis:                       7.441   Cond. No.                     4.99e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.99e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "condo_subset = condo.loc[(condo['area']<1500) & (condo['remaining_years'] > 99)]\n",
    "\n",
    "model = smf.ols('price ~ segment + area', condo_subset)\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fitted model for each category is given as follows\n",
    "\\begin{align}\n",
    "\\text{CCR condos where }d_{\\text{OCR}}=0\\text{ and }d_{\\text{RCR}}=0: ~&\\hat{y}_{\\text{price}} = \\hat{\\beta}_0 + \\hat{\\beta}_1d_{\\text{OCR}} + \\hat{\\beta}_2d_{\\text{RCR}} + \\hat{\\beta}_3 x_{\\text{area}} = \\hat{\\beta}_0 + \\hat{\\beta}_3x_{\\text{area}} \\\\\n",
    "\\text{OCR condos where }d_{\\text{OCR}}=1\\text{ and }d_{\\text{RCR}}=0: ~&\\hat{y}_{\\text{price}} = \\hat{\\beta}_0 + \\hat{\\beta}_1d_{\\text{OCR}} + \\hat{\\beta}_2d_{\\text{RCR}} + \\hat{\\beta}_3 x_{\\text{area}} = (\\hat{\\beta}_0 + \\hat{\\beta}_1) + \\hat{\\beta}_3x_{\\text{area}} \\\\\n",
    "\\text{RCR condos where }d_{\\text{OCR}}=0\\text{ and }d_{\\text{RCR}}=1: ~&\\hat{y}_{\\text{price}} = \\hat{\\beta}_0 + \\hat{\\beta}_1d_{\\text{OCR}} + \\hat{\\beta}_2d_{\\text{RCR}} + \\hat{\\beta}_3 x_{\\text{area}} = (\\hat{\\beta}_0 + \\hat{\\beta}_2) + \\hat{\\beta}_3x_{\\text{area}} \\\\\n",
    "\\end{align}\n",
    "so clearly the interpretations of model parameters are:\n",
    "- $\\hat{\\beta}_0$: the intercept of condos located in the CCR segment.\n",
    "- $\\hat{\\beta}_1$: the difference in intercepts of OCR condos compared with CCR condos.\n",
    "- $\\hat{\\beta}_2$: the difference in intercepts of RCR condos compared with CCR condos.\n",
    "- $\\hat{\\beta}_3$: the slope parameter of $x_{\\text{area}}$ for condos in all segments.\n",
    "\n",
    "We thus conclude that the intercept $\\hat{\\beta}_0$ is the intercept of the **baseline** category, and slope parameters $\\hat{\\beta}_1$ and $\\hat{\\beta}_2$ of dummy variables indicate the difference between the corresponding category compared with the baseline case. That is why the baseline case is also called **benchmark** or **reference** case. For the other independent variable $x_{\\text{area}}$, all categories share the same slope parameter $\\hat{\\beta}_3$. The SRF curves are illustrated by the following graph.\n",
    "\n",
    "<img src=\"https://github.com/XiongPengNUS/dao_resources/blob/main/condo_price_areas_seg.png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Example 6:</b> Given the dataset 'condo.csv' and consider all <b>freehold</b> condos <b>smaller than 1500 square feet</b>, run a regression model with the total price $y_{\\text{price}}$ being the dependent variable and the categorical variable $x_{\\text{district_code}}$ and the numerical variable $x_{\\text{area}}$ being the independent variables. \n",
    "</div>\n",
    "\n",
    "In this example, we consider the column <code>district_code</code> in our regression model. This is a slightly different case because all values of the column are integers, so it will be recognized by Python as a numerical variable by default. This column <code>district_code</code> can be converted to a categorical variable by using the function <code>C()</code> in the string type formula, as the following code cell.\n",
    "c可以把numeric变成category。因为district_code变成数字是没有意义的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  price   R-squared:                       0.661\n",
      "Model:                            OLS   Adj. R-squared:                  0.660\n",
      "Method:                 Least Squares   F-statistic:                     487.6\n",
      "Date:                Sun, 19 Sep 2021   Prob (F-statistic):               0.00\n",
      "Time:                        14:50:31   Log-Likelihood:                -82040.\n",
      "No. Observations:                5767   AIC:                         1.641e+05\n",
      "Df Residuals:                    5743   BIC:                         1.643e+05\n",
      "Df Model:                          23                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "Intercept               5.017e+05   8.63e+04      5.813      0.000    3.33e+05    6.71e+05\n",
      "C(district_code)[T.2]   5.529e+04   1.04e+05      0.530      0.596   -1.49e+05     2.6e+05\n",
      "C(district_code)[T.3]  -1.516e+05   9.75e+04     -1.555      0.120   -3.43e+05    3.95e+04\n",
      "C(district_code)[T.4]   -705.4178   1.02e+05     -0.007      0.994   -2.01e+05       2e+05\n",
      "C(district_code)[T.5]  -4.542e+05   8.61e+04     -5.275      0.000   -6.23e+05   -2.85e+05\n",
      "C(district_code)[T.8]  -2.252e+05   8.99e+04     -2.505      0.012   -4.02e+05    -4.9e+04\n",
      "C(district_code)[T.9]   6.842e+05   8.54e+04      8.009      0.000    5.17e+05    8.52e+05\n",
      "C(district_code)[T.10]  2.983e+05   8.49e+04      3.513      0.000    1.32e+05    4.65e+05\n",
      "C(district_code)[T.11]  7.723e+04   8.57e+04      0.902      0.367   -9.07e+04    2.45e+05\n",
      "C(district_code)[T.12] -3.861e+05   8.94e+04     -4.319      0.000   -5.61e+05   -2.11e+05\n",
      "C(district_code)[T.13] -3.756e+05   9.75e+04     -3.852      0.000   -5.67e+05   -1.84e+05\n",
      "C(district_code)[T.14] -6.318e+05   8.86e+04     -7.134      0.000   -8.05e+05   -4.58e+05\n",
      "C(district_code)[T.15]  -626.4263   8.48e+04     -0.007      0.994   -1.67e+05    1.66e+05\n",
      "C(district_code)[T.16] -6.226e+05   8.76e+04     -7.106      0.000   -7.94e+05   -4.51e+05\n",
      "C(district_code)[T.17] -9.142e+05   8.62e+04    -10.610      0.000   -1.08e+06   -7.45e+05\n",
      "C(district_code)[T.18] -8.461e+05   1.06e+05     -7.945      0.000   -1.05e+06   -6.37e+05\n",
      "C(district_code)[T.19]  -3.26e+05   8.68e+04     -3.757      0.000   -4.96e+05   -1.56e+05\n",
      "C(district_code)[T.20] -3.401e+05    9.7e+04     -3.505      0.000    -5.3e+05    -1.5e+05\n",
      "C(district_code)[T.21] -4.054e+05   8.49e+04     -4.776      0.000   -5.72e+05   -2.39e+05\n",
      "C(district_code)[T.23]  -6.11e+05   8.58e+04     -7.119      0.000   -7.79e+05   -4.43e+05\n",
      "C(district_code)[T.26] -5.393e+05   9.07e+04     -5.944      0.000   -7.17e+05   -3.61e+05\n",
      "C(district_code)[T.27] -9.947e+05   1.02e+05     -9.725      0.000    -1.2e+06   -7.94e+05\n",
      "C(district_code)[T.28] -8.418e+05    1.2e+05     -7.001      0.000   -1.08e+06   -6.06e+05\n",
      "area                    1185.8182     17.815     66.563      0.000    1150.894    1220.742\n",
      "==============================================================================\n",
      "Omnibus:                     1586.650   Durbin-Watson:                   1.643\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             6479.764\n",
      "Skew:                           1.303   Prob(JB):                         0.00\n",
      "Kurtosis:                       7.492   Cond. No.                     9.38e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 9.38e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "condo_subset = condo.loc[(condo['area']<1500) & (condo['remaining_years'] > 99)]\n",
    "\n",
    "model = smf.ols('price ~ C(district_code) + area', condo_subset)\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction terms <a id=\"subsection8.3\"></a>\n",
    "In previous examples, dummy variables were used so the SRF curves took different intercepts for different categories. The slope parameter of the numerical variable $x_{\\text{area}}$, however, remained the same value for all categories. It implied that condos in different categories (types, segments, or districts) have the same per square feet price, which is not exactly true in the property market. For example, we expect to see the per square feet price for the new sale condos higher than the resale condos. In other words, the slope parameter of $x_{\\text{area}}$ for the \"new sale\" category should be larger than that of the \"resale\" category. \n",
    "\n",
    "In regression models, we could devise different slope parameters for various categories by introducing **interaction terms** to the formula, as demonstrated by the next example.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Example 7:</b> Given the dataset 'condo.csv' and consider all condos that:\n",
    "    <li> in district 5, </li>\n",
    "    <li> has an area smaller than 1500 square feet, </li>\n",
    "    <li> has a tenure of no more than 99 years remaining. </li>\n",
    "    Run a regression model with the total price $y_{\\text{price}}$ being the dependent variable, $x_{\\text{type}}$ and $x_{\\text{area}}$ being the independent variables. The slope parameter of $x_{\\text{area}}$ takes different values for categories \"resale\" and \"new sale\". \n",
    "</div>\n",
    "\n",
    "Let $d_{\\text{resale}}$ be the dummy variable that equals to one if a condo is resale and zero otherwise, then the model formula can be written as\n",
    "$$\n",
    "y_{\\text{price}} = \\beta_0 + \\beta_1 d_{\\text{resale}} + \\beta_2 x_{\\text{area}} + \\beta_3 d_{\\text{resale}}\\cdot x_{\\text{area}} + u.\n",
    "$$\n",
    "The fourth term of the equation is an interaction term that considers the product of the dummy variable $d_{\\text{resale}}$ and the numerical variable $x_{\\text{area}}$. Apparently, the fitted models for these two categories can be written as\n",
    "\\begin{align}\n",
    "\\text{Resale condos where }d_{\\text{resale}}=1: ~&\\hat{y}_{\\text{price}} = \\hat{\\beta}_0 + \\hat{\\beta}_1d_{\\text{resale}} + \\hat{\\beta}_2x_{\\text{area}} + \\hat{\\beta}_3 d_{\\text{resale}}\\cdot x_{\\text{area}} = (\\hat{\\beta}_0 + \\hat{\\beta}_1) + (\\hat{\\beta}_2 + \\hat{\\beta}_3)x_{\\text{area}} \\\\\n",
    "\\text{New sale condos where }d_{\\text{resale}}=0: ~&\\hat{y}_{\\text{price}} = \\hat{\\beta}_0 + \\hat{\\beta}_1 d_{\\text{resale}} + \\hat{\\beta}_2x_{\\text{area}} + \\hat{\\beta}_3 d_{\\text{resale}}\\cdot x_{\\text{area}} = \\hat{\\beta}_0 + \\hat{\\beta}_2x_{\\text{area}},\n",
    "\\end{align}\n",
    "where the slope parameter of $x_{\\text{area}}$ is $\\hat{\\beta}_2+\\hat{\\beta}_3$ for \"resale\" condos and $\\hat{\\beta}_2$ for \"new sale\" condos.\n",
    "\n",
    "For the <code>statsmodels</code> package, there are two ways of implementing the interaction terms, as following two code cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  price   R-squared:                       0.833\n",
      "Model:                            OLS   Adj. R-squared:                  0.832\n",
      "Method:                 Least Squares   F-statistic:                     2317.\n",
      "Date:                Sun, 19 Sep 2021   Prob (F-statistic):               0.00\n",
      "Time:                        14:50:31   Log-Likelihood:                -18388.\n",
      "No. Observations:                1402   AIC:                         3.678e+04\n",
      "Df Residuals:                    1398   BIC:                         3.681e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "Intercept            1.408e+05   1.27e+04     11.051      0.000    1.16e+05    1.66e+05\n",
      "type[T.Resale]       1.081e+05   3.24e+04      3.333      0.001    4.45e+04    1.72e+05\n",
      "area                 1080.5225     14.100     76.631      0.000    1052.862    1108.183\n",
      "type[T.Resale]:area  -258.8491     30.355     -8.527      0.000    -318.395    -199.304\n",
      "==============================================================================\n",
      "Omnibus:                       92.170   Durbin-Watson:                   1.960\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              254.409\n",
      "Skew:                           0.332   Prob(JB):                     5.70e-56\n",
      "Kurtosis:                       4.979   Cond. No.                     1.14e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.14e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "condo_subset = condo.loc[(condo['district_code']==5) & \n",
    "                         (condo['area']<1500) & \n",
    "                         (condo['remaining_years']<100)]\n",
    "\n",
    "model = smf.ols('price ~ type*area', condo_subset) #create3个terms\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  price   R-squared:                       0.833\n",
      "Model:                            OLS   Adj. R-squared:                  0.832\n",
      "Method:                 Least Squares   F-statistic:                     2317.\n",
      "Date:                Sun, 19 Sep 2021   Prob (F-statistic):               0.00\n",
      "Time:                        14:50:31   Log-Likelihood:                -18388.\n",
      "No. Observations:                1402   AIC:                         3.678e+04\n",
      "Df Residuals:                    1398   BIC:                         3.681e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "Intercept            1.408e+05   1.27e+04     11.051      0.000    1.16e+05    1.66e+05\n",
      "type[T.Resale]       1.081e+05   3.24e+04      3.333      0.001    4.45e+04    1.72e+05\n",
      "area                 1080.5225     14.100     76.631      0.000    1052.862    1108.183\n",
      "type[T.Resale]:area  -258.8491     30.355     -8.527      0.000    -318.395    -199.304\n",
      "==============================================================================\n",
      "Omnibus:                       92.170   Durbin-Watson:                   1.960\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              254.409\n",
      "Skew:                           0.332   Prob(JB):                     5.70e-56\n",
      "Kurtosis:                       4.979   Cond. No.                     1.14e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.14e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "condo_subset = condo.loc[(condo['district_code']==5) & \n",
    "                         (condo['area']<1500) & \n",
    "                         (condo['remaining_years']<100)]\n",
    "\n",
    "model = smf.ols('price ~ type + area + type:area', condo_subset)\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the results are exactly the same, and the SRF curves for both categories are displayed by the following graph.\n",
    "\n",
    "<img src=\"https://github.com/XiongPengNUS/dao_resources/blob/main/condo_price_areas_type_int.png?raw=true\">\n",
    "\n",
    "According to the higher adjusted $R^2$ value, this model provides a better fit compared with the model without an interaction term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case studies <a id=\"section9\"></a>\n",
    "\n",
    "### Case study 1: Singapore condo prices <a id=\"subsection9.1\"></a>\n",
    "Please design a explanatory model for the Singapore condo price data. The dependent variable should be the total price, or the unit price, and you may use any nonlinear or interaction terms to improve the adjusted $R^2$ value. In order to make it simpler, let us only focus on **district 5**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "condo = pd.read_csv('.csv')\n",
    "condo.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
